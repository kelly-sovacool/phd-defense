---
title: "Improving machine learning models for microbiome analysis"
subtitle: "and democratizing data science along the way"
author: "Kelly Sovacool"
date: 2023-06-22
date-format: MMM DD, YYYY
mainfont: Helvetica
format:
  revealjs:
    theme: custom.scss
    embed-resources: false
    logo: img/block_m-hex.png
execute:
  eval: true
  echo: false
knitr:
  opts_chunk:
    fig.path: figures/
---

```{r deps}
library(cowplot)
library(ggsankey)
library(glue)
library(ggtext)
library(knitr)
library(schtools)
library(tidyverse)
library(yaml)

metadat_cases <- read_csv('papers/severe-cdi/data/process/cases_full_metadata.csv') %>%
    filter(!(is.na(idsa) & is.na(allcause) & is.na(attrib) & is.na(pragmatic)))
perf_dat <- read_csv('papers/severe-cdi/results/performance_results_aggregated.csv') %>%
    rename(AUROC = AUC,
           AUPRC = prAUC)  %>%
  mutate(
    outcome = factor(case_when(outcome == 'idsa' ~ 'IDSA\n severity',
                        outcome == 'attrib' ~ 'Attributable\n severity',
                        outcome == 'allcause' ~ 'All-cause\n severity',
                        outcome == 'pragmatic' ~ 'Pragmatic\n severity',
                        TRUE ~ NA_character_), levels = c('IDSA\n severity',
                           'All-cause\n severity',
                           'Attributable\n severity',
                           'Pragmatic\n severity'))
  )
feat_dat <- read_csv('papers/severe-cdi/results/feature-importance_results_aggregated.csv')
sensspec_dat <- read_csv('papers/severe-cdi/results/sensspec_results_aggregated.csv')
```

## What is a microbiome? {.hidden}

Community of microorganisms that inhabit a shared ecosystem

TODO

## The human gut microbiome changes during diseases

:::{.smaller}
- Irritable bowel diseases
- Colorectal cancer
- _Clostridioides difficile_ infection
:::

:::{.notes}
- Changes in the taxonomic composition and metabolic activity of human microbiomes have been observed in several diseases including colorectal cancer (CRC) and Clostridioides difficile infection (CDI).
- **CRC** - enrichment for bacteria that produce enterotoxins in CRC gut microbiomes.
- **CDI** - treatment with antibiotics alters the taxonomic composition of the gut microbiome, allowing _C. diff_ to colonize the gut.

- For depictions of gut microbiome:
    - https://norgenbiotek.com/blog/gut-microbiome-and-its-effects-human-health
    - https://commonfund.nih.gov/sites/default/files/Vector%20intestines%20with%20bacteria%2C%20germs%20and%20magnifier%20-467885302.jpg
    - https://medicalxpress.com/news/2019-10-commonly-drugs-profoundly-affecting-gut.html
- ML models have the potential to improve the early detection of CRC, inform clinicians on which CDI patients may be most at risk of experiencing a severe case, or more generally contribute to our understanding of how the gut microbiome changes during disease states.
:::

## The human gut microbiome changes during _C. difficile_ infection

![](img/cdiff-infection.png)

:::{.aside}
Created with [BioRender](biorender.com){fig-align="center"}
:::

:::{.notes}
- **CDI** - treatment with antibiotics alters the taxonomic composition of the gut microbiome, allowing _C. diff_ to colonize the gut.
- mouse studies have found differences resistance to colonization, time to clearance, and severe outcomes based on the initial state of the gut microbiome.
- ML models have the potential to improve the early detection of CRC, inform clinicians on which CDI patients may be most at risk of experiencing a severe case, or more generally contribute to our understanding of how the gut microbiome changes during disease states.
:::

## How to study the gut microbiome

![](img/microbiome-research.png){height=600px fig-align="center"}

:::{.aside}
Created with [BioRender](biorender.com)
:::

:::{.notes}
and do it all reproducibly
:::

## Machine learning for health care {.hidden}

TODO diagnosis and prognosis

Possible causative role of the microbiome in disease etiology

:::{.notes}
mechanisms are not entirely understood.
not always clear whether the disease causes the microbiome to change, the
change in the microbiome causes the disease, or some combination.

- CDI: antibiotics disrupts the community and allows cdiff to colonize, but what
causes some people to develop severe outcomes vs clear the infection easily?
    - Bile acids metabolized by the gut bacteria can inhibit C. difficile growth and affect toxin production (4, 10, 11). Bacteria in the gut also can compete more directly with C. difficile through antibiotic production or nutrient consumption
- CRC: some CRC patients have strains of _E. coli_ that produce enterotoxins, but not all.
    - FIT cartridge sensitivity (true pos rate): 70% (early stage) to 80% (late stage)
    - colonoscopy sensitivity: 78% to 93%
    - detecting CRC early improves prognosis, but colonoscopies are invasive.
- Baxter et al: "The microbiota-based random forest model detected 91.7 % of cancers and 45.5 % of adenomas while FIT alone detected 75.0 % and 15.7 %, respectively. Of the colonic lesions missed by FIT, the model detected 70.0 % of cancers and 37.7 % of adenomas. We confirmed known associations of Porphyromonas assaccharolytica, Peptostreptococcus stomatis, Parvimonas micra, and Fusobacterium nucleatum with CRC. Yet, we found that the loss of potentially beneficial organisms, such as members of the Lachnospiraceae, was more predictive for identifying patients with adenomas when used in combination with FIT."

- However, these changes are not universal across individuals or datasets.
- Mouse experiments indicate a possible causative role of the microbiome.
    - fecal matter transplant from susceptible to germ-free mice
    - predict colonization following Cdiff challenge

- Open problems, and opportunities:
    - Understand the role of the gut microbiome in gut diseases.
    - Identify biomarkers to improve diagnostic and prognostic tools.

Traditional microbial ecology methods aren't sufficient to distinguish between disease states.
individual microbes aren't enough to explain it; something more complex is going on

- high dimensionality: 20k OTUs
:::

## Overview

:::{.column width="72%"}
1. Improve methods for processing microbiome data.
1. Predict severe _C. difficile_ infections from gut microbiome composition.
1. Contribute to democratizing data science.
:::

## How to characterize microbiomes

![](img/amplicon-vs-metagenomics.png){height=600px fig-align="center"}

:::{.aside}
Lee (2019). [JOSE](https://astrobiomike.github.io/misc/amplicon_and_metagen)
:::

:::{.notes}
pros & cons of amplicon sequencing vs metagenomics

fundamentally different questions

note different taxa: archaea, bacteria, fungi, protists, viruses
:::

## Difficulties in bacterial taxonomy

- There is no consensus definition of a bacterial species.
- Amplicon sequences do not contain enough information to identify bacteria at the species level.
- Many bacteria have multiple copies of the 16S rRNA gene, the most popular marker gene for amplicon sequencing bacterial communities.

:::{.notes}
why OTUs?

- Some bacteria have multiple copies of the 16S rRNA gene. Using every sequence (ASV level) as a feature would split them into separate taxonomic groups.
- Database-independent clustering methods allow exploring microbial "dark matter".
- Case study in classifying colorectal cancer patients: the OTU, genus, and family levels perform best.
:::

## Clustering amplicon sequences into Operational Taxonomic Units (OTUs)

#### _De novo_

![](img/de-novo-clustering-0.png){fig-align="center" height=500px}

:::{.aside}
Created with [BioRender](biorender.com)
:::

## Clustering amplicon sequences into Operational Taxonomic Units (OTUs)

#### _De novo_

![](img/de-novo-clustering-1.png){fig-align="center" height=500px}

:::{.aside}
Created with [BioRender](biorender.com)
:::

## Clustering amplicon sequences into Operational Taxonomic Units (OTUs)

#### _De novo_

![](img/de-novo-clustering-2.png){fig-align="center" height=500px}

:::{.aside}

Created with [BioRender](biorender.com)
:::

## Clustering amplicon sequences into Operational Taxonomic Units (OTUs)

#### Reference-based

![](img/reference-clustering-1.png){fig-align="center" height=500px}

:::{.aside}
Created with [BioRender](biorender.com)
:::

## Clustering amplicon sequences into Operational Taxonomic Units (OTUs)

#### Reference-based

![](img/reference-clustering-2.png){fig-align="center" height=500px}

:::{.aside}
Created with [BioRender](biorender.com)
:::

:::{.notes}
Limitations of existing clustering methods

- _De novo_ clustering results in inconsistent OTUs when adding new data.
- Reference-based clustering results in lower quality OTUs than _de novo_.
:::

## OptiFit
### reference-based clustering to _de novo_ OTUs

![](img/optifit-clustering-1.png){fig-align="center" height=500px}

:::{.aside}
Created with [BioRender](biorender.com)
:::

## OptiFit
### reference-based clustering to _de novo_ OTUs

![](img/optifit-clustering-2.png){fig-align="center" height=500px}

:::{.aside}
Created with [BioRender](biorender.com)
:::

```{r optifit}
mutate_perf <- function(dat) {
  dat %>%
    mutate(
      mem_mb = max_rss,
      mem_gb = mem_mb / 1024
    ) %>%
    rename(sec = s)
}
select_cols <- function(dat) {
  dat %>%
    select(dataset, strategy, method, tool, mcc, sec, mem_gb, fraction_mapped)
}

opticlust <- read_tsv("papers/optifit/subworkflows/1_prep_samples/results/opticlust_results.tsv") %>%
  full_join(read_tsv("papers/optifit/subworkflows/1_prep_samples/results/dataset_sizes.tsv")) %>%
  mutate_perf() %>%
  mutate(strategy = method, fraction_mapped = NA)
optifit_dbs <- read_tsv("papers/optifit/subworkflows/2_fit_reference_db/results/optifit_dbs_results.tsv") %>%
  mutate_perf()
optifit_split <- read_tsv("papers/optifit/subworkflows/3_fit_sample_split/results/optifit_split_results.tsv") %>%
  filter(ref_frac == 0.5, ref_weight == "simple") %>%
  mutate_perf()
optifit_all <- list(
  optifit_dbs %>%
    mutate(strategy = glue("database_{ref}")),
  optifit_split %>%
    mutate(strategy = "self-split")
) %>%
  reduce(full_join)
vsearch <- read_tsv("papers/optifit/subworkflows/4_vsearch/results/vsearch_results.tsv") %>%
  mutate_perf() %>%
  mutate(strategy = case_when(
    method == "de_novo" ~ method,
    TRUE ~ as.character(glue("database_{ref}"))
  ))
mothur_vsearch <- list(optifit_all, opticlust, vsearch) %>%
  lapply(select_cols) %>%
  reduce(bind_rows) %>%
  mutate(
    method = as.character(method),
    strategy = as.character(strategy)
  ) %>%
  mutate(fraction_mapped = case_when(
    method %>% as.character() != "closed" ~ NA_real_,
    TRUE ~ fraction_mapped
  )) %>%
  pivot_longer(c(mcc, fraction_mapped, sec),
    names_to = "metric"
  ) %>%
  mutate(
    metric = factor(
      case_when(
        metric == "mcc" ~ "MCC",
        metric == "fraction_mapped" ~ "Fraction Mapped",
        metric == "sec" ~ "Runtime (sec)",
        TRUE ~ metric
      ),
      levels = c("MCC", "Fraction Mapped", "Runtime (sec)")
    ),
    strategy = factor(
      case_when(
        strategy == "de_novo" ~ "_de novo_",
        strategy == "database_rdp" ~ "db: RDP",
        strategy == "database_silva" ~ "db: SILVA",
        strategy == "database_gg" ~ "db: Greengenes",
        TRUE ~ strategy
      ),
      levels = c(
        "db: RDP", "db: SILVA", "db: Greengenes",
        "self-split", "_de novo_"
      )
    ),
    method = factor(
      case_when(
        method == "de_novo" ~ "_de novo_",
        TRUE ~ method
      ),
      levels = c("open", "closed", "_de novo_")
    )
  )

med_iqr <- function(x) {
  return(data.frame(
    y = median(x),
    ymin = quantile(x)[2],
    ymax = quantile(x)[4]
  ))
}

color_list <- list(
  `OptiClust (_de novo_) or OptiFit` = RColorBrewer::brewer.pal(3, "Set1")[1],
  VSEARCH = RColorBrewer::brewer.pal(3, "Set1")[2]
)
color_labels <- lapply(
  names(color_list),
  function(name) {
    glue("<span style = 'color:{color_list[[name]]};'>{name}</span>")
  }
) %>% unlist()

plot_results_sum <- function(metric_str) { mothur_vsearch %>%
  filter(dataset == 'human', metric == metric_str) %>%
  mutate(tool = case_when(
    tool == "vsearch" ~ "VSEARCH",
    tool == "mothur" ~ "OptiClust (_de novo_) or OptiFit"
  )) %>%
  ggplot(aes(value, strategy, color = tool, shape = method)) +
  # stat_summary(geom = "linerange",
  #              fun.data = med_iqr,
  #              position = position_dodge(width = 0.4)) +
  stat_summary(
    geom = "point",
    fun = median,
    size = 3,
    position = position_dodge(width = 0.4)
  ) +
  scale_shape_manual(values = list(open = 1, closed = 19, `_de novo_` = 17),
    guide = guide_legend(label.position = 'top')) +
  scale_color_manual(
    values = color_list,
    labels = color_labels,
    guide = guide_legend(label.position = 'top')
  ) +
  labs(x = metric_str, y = "") +
  theme_bw() +
  theme(
    strip.placement = "outside",
    strip.background = element_blank(),
    axis.text.y = element_markdown(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.title = element_blank(),
    legend.text = element_markdown(),
    legend.position = "top",
    legend.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "pt"),
    legend.spacing.x = unit(0.5, "pt"),
    plot.margin = unit(x = c(0, 0, 0, 0), units = "pt"),
    text = element_text(size = 14, family = 'Helvetica')
  ) +
  guides(
    shape = guide_legend(order = 1),
    colour = guide_legend(
      override.aes = list(size = -1)
    )
  )
}
mcc <- plot_results_sum('MCC')
optifit_legend <- get_legend(mcc)
mcc <- mcc + theme(legend.position = 'none')
frac <- plot_results_sum("Fraction Mapped") +
    theme(axis.text.y = element_blank(), legend.position = 'none')
sec <- plot_results_sum('Runtime (sec)') +
    theme(axis.text.y = element_blank(), legend.position = 'none')
```

## OptiFit benchmarking results

```{r mcc}
#| out-width: 1000px
#| out-height: 450px
plot_grid(optifit_legend,
    plot_grid(mcc, NULL, NULL, nrow = 1, rel_widths = c(1.3, 1, 1)),
    ncol = 1, rel_heights = c(0.1, 1)
)
```

:::{.aside}
Sovacool _et al._ (2022). [mSphere](https://doi.org/10.1128/msphere.00916-21)
:::

## OptiFit benchmarking results

```{r frac}
#| out-width: 1000px
#| out-height: 450px
plot_grid(optifit_legend,
    plot_grid(mcc, frac, NULL, nrow = 1, rel_widths = c(1.3, 1, 1)),
    ncol = 1, rel_heights = c(0.1, 1)
)
```

:::{.aside}
Sovacool _et al._ (2022). [mSphere](https://doi.org/10.1128/msphere.00916-21)
:::

## OptiFit benchmarking results

```{r sec}
#| out-width: 1000px
#| out-height: 450px
plot_grid(optifit_legend,
    plot_grid(mcc, frac, sec, nrow = 1, rel_widths = c(1.3, 1, 1)),
    ncol = 1, rel_heights = c(0.1, 1)
)
```

:::{.aside}
Sovacool _et al._ (2022). [mSphere](https://doi.org/10.1128/msphere.00916-21)
:::

## OptiFit for ML applications

![](img/armour_optifit_ml.png)

:::{.aside}
Armour _et al._ (2023). [bioRxiv](10.1101/2022.09.01.506299)
:::

## Overview

:::{.column width="72%"}
1. Improve methods for processing microbiome data.
1. **Predict severe _C. difficile_ infections from gut microbiome composition.**
1. Contribute to democratizing data science.
:::

## _C. difficile_ infection (CDI)

![](img/Cdiff-Factsheet-P_impact-risk.png){height=500px}

:::{.aside}
[cdc.gov/cdiff](https://www.cdc.gov/cdiff/)
:::

## Clinical data predict complicated CDI

:::{.column width="60%"}
![](img/li_ehr_auroc.jpeg)

::::{.smaller-text}
median AUROC: **0.69**
::::
:::

:::{.column width="35%" .smaller-text}
<br>
- Electronic health record (EHR) data used as features to predict whether disease-related complications occurred.
- Motivation: inform clinicians on which CDI patients may be most at risk of severe CDI.
:::

:::{.aside}
Li _et al._ (2019). [OFID](https://doi.org/10.1093/ofid/ofz186)
:::

:::{.notes}
TODO summarize dieterle & rao papers too

CDI treatment. Li et al. (2019). https://academic.oup.com/ofid/article/6/5/ofz186/5475497
"The development and validation of EHR-based risk stratification models for predicting complicated CDI could eventually help clinicians tailor treatments to individuals. On the day of CDI diagnosis, a patient's estimated risk for complications could serve as an adjunct, easily obtainable resource for clinical decision support. Treatment decisions such as whether to use high-dose vancomycin or perform a loop ileostomy with antegrade vancomycin infusions [23] often do not occur until complicated CDI has already set in. In severe cases, early aggressive therapy can positively impact the course. However, invasive treatments such as enemas (fecal microbiota transplantation or vancomycin) and surgery are optimally used in only select patients, and such decisions lack the rigorous guidelines associated with initial treatment."

Would help clinicians tailor treatment options early on. Whether to go with an aggressive treatment plan or not.
:::

## {}

<br>

:::{.big-middle}
Can we use the composition of the gut microbiome to predict CDI severity?
:::

## How to define CDI severity {.smaller}

<br>

![](papers/severe-cdi/figures/severity_flowchart.png){height=600px}

:::{.absolute width="35%" top=70 left=180 .narrow-frame .fragment}
`r format_number(nrow(metadat_cases))` CDI patient stool samples collected on the day of diagnosis
:::

:::{.fragment .filled-box .absolute top=300 left=850}
```{r sample_counts}
counts <- read_csv('papers/severe-cdi/results/count_table_full.csv') %>%
  mutate(Severity = factor(Severity, levels = c('IDSA', 'All-cause', 'Attributable', 'Pragmatic')))
counts %>%
    filter(Severity != 'Pragmatic') %>%
    kable(format.args = list(big.mark = ',')) %>%
    kableExtra::kable_styling(font_size = 20)
```
:::

:::{.fragment .filled-box .absolute top=300 left=850}
```{r sample_counts_pragmatic}
counts %>%
    kable(format.args = list(big.mark = ',')) %>%
    kableExtra::kable_styling(font_size = 20)
```
:::

## Training machine learning models

![](img/topcuoglu_framework.jpeg){height=600px}

:::{.aside}
TopÃ§uoÄŸlu _et al._ (2020). [mBio](https://doi.org/10.1128/mBio.00434-20)
:::

## Model performance {.smaller}
Random Forests trained on 100x train/test splits of each dataset

```{r roc_curves}
#| out-width: 100%
roc_dat <- read_csv('papers/severe-cdi/results/roccurve_results_aggregated.csv') %>%
  mutate(outcome = factor(outcome, levels = c('idsa', 'allcause', 'attrib', 'pragmatic'))) %>% 
  mutate(dataset = case_when(dataset == 'full' ~ 'Full datasets',
                             dataset == 'int' ~ 'Intersection',
                             TRUE ~ NA_character_)) %>% 
  dplyr::mutate(specificity = round(specificity, 1)) %>%
  dplyr::group_by(specificity, dataset, outcome) %>%
  dplyr::summarise(
    mean_sensitivity = mean(sensitivity),
    upper = quantile(sensitivity, 0.95),
    lower = quantile(sensitivity, 0.05)
  ) %>%
  dplyr::mutate(
    upper = dplyr::case_when(
      upper > 1 ~ 1,
      TRUE ~ upper
    ),
    lower = dplyr::case_when(
      lower < 0 ~ 0,
      TRUE ~ lower
    )
  )

roc_plot <- roc_dat %>%
  filter(dataset != 'Intersection')  %>%
  ggplot() +
  geom_ribbon(aes(x = specificity, ymin = lower, ymax = upper, fill = outcome), 
              alpha = 0.08) +
  geom_line(aes(x = specificity, y = mean_sensitivity, color = outcome), alpha=0.6) +
  #geom_point(data = roc_risk_pct, aes(x = Specificity, y = mean_sensitivity, color = outcome)) +
  geom_abline(
    intercept = 1,
    slope = 1,
    linetype = "dashed",
    color = "grey50"
  ) +
  scale_color_manual(values = c(idsa = "#1B9E77", 
                                attrib = "#D95F02", 
                                allcause = "#7570B3", 
                                pragmatic = "#E7298A"),
                     guide = guide_legend(label.position = 'top')) +
  scale_fill_manual(values = c(idsa = "#1B9E77", 
                               attrib = "#D95F02", 
                               allcause = "#7570B3", 
                               pragmatic = "#E7298A"),
                    labels = c(idsa='IDSA', attrib='Attributable', 
                               allcause='All-cause', pragmatic='Pragmatic')
  ) +
  guides(fill = 'none') +
  scale_y_continuous(expand = c(0, 0), limits = c(-0.01, 1.01)) +
  scale_x_reverse(expand = c(0, 0), limits = c(1.01,-0.01)) +
  coord_equal() +
  labs(x = "Specificity", y = "Sensitivity") +
  theme_sovacool() +
  theme(text = element_text(size = 14, family = 'Helvetica'),
        legend.position = 'top',
        legend.title = element_blank(),
        strip.background = element_blank(),
        panel.spacing = unit(10, 'pt'),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        plot.margin = margin(0,5,0,0))

auroc_plot <- perf_dat %>%
    filter(dataset == 'full') %>%
    rename(trainset = cv_metric_AUC,
           testset = AUROC) %>%
    pivot_longer(c(trainset, testset),
                 names_to = "data_partition",
                 values_to = 'AUROC'
                 )  %>%
    ggplot(aes(x = AUROC, y = outcome, color = data_partition)) +
    geom_vline(xintercept = 0.5, linetype = "dashed") +
    geom_boxplot() +
    stat_summary(fun = median,
                 geom = "text",
                 show.legend = FALSE,
                 mapping = aes(label = round(after_stat(x),2)),
                 position = position_nudge(x = 0.2, y = c(-0.1, 0.1))) +
    scale_color_grey() +
    scale_x_continuous(expand = c(0, 0), limits = c(0.3, 1.01)) +
    theme_sovacool() +
    theme(
        plot.margin = unit(x = c(0, 5, 0, 10), units = "pt"),
        axis.title.y = element_blank(),
        legend.position = 'top',
        legend.margin = margin(0, 0, 0, 0, unit = "pt"),
        legend.title = element_blank(),
        text = element_text(size = 14, family = 'Helvetica'),
    )
plot_grid(roc_plot, NULL, nrow = 1, rel_widths = c(0.8,1),
          align = 'h', axis = 'tb')
```


:::{.notes}
ROC = trade-off between correctly predicting positive vs negative samples.

sensitivity/recall = $TPR = \frac{TP}{TP + FN}$

Out of all positive samples, how many correctly predicted positive.

specificity = $TNR = \frac{TN}{TN + FP} = 1 - FPR$

Out of all negative samples, how many correctly predicted negative.

$FPR = \frac{FP}{FP + TN}$

Out of all negative samples, how many incorrectly predicited positive.
:::

## Model performance {.smaller}
Random Forests trained on 100x train/test splits of each dataset

```{r auroc}
plot_grid(roc_plot, auroc_plot, nrow = 1, rel_widths = c(0.8,1),
          align = 'h', axis = 'tb')
```

:::{.absolute top=20 right=100 width="250" height="80" .medium-text .frame-box .fragment}
EHR-based models from Li _et al._

Median AUROC: **0.69**
:::

:::{.notes}
ROC = trade-off between correctly predicting positive vs negative samples.

sensitivity/recall = $TPR = \frac{TP}{TP + FN}$

Out of all positive samples, how many correctly predicted positive.

specificity = $TNR = \frac{TN}{TN + FP} = 1 - FPR$

Out of all negative samples, how many correctly predicted negative.

$FPR = \frac{FP}{FP + TN}$

Out of all negative samples, how many incorrectly predicited positive.
:::

## Model performance on severe cases {.smaller}
Random Forests trained on 100x train/test splits of each dataset

```{r prc}
prcurve_dat <- read_csv('papers/severe-cdi/results/prcurve_results_aggregated.csv') %>%
  mutate(outcome = factor(outcome, levels = c('idsa', 'allcause', 'attrib', 'pragmatic'))) %>%
  mutate(dataset = case_when(dataset == 'full' ~ 'Full datasets',
                             dataset == 'int' ~ 'Intersection',
                             TRUE ~ NA_character_)) %>%
  dplyr::mutate(recall = round(recall, 2)) %>%
  dplyr::group_by(recall, dataset, outcome) %>%
  dplyr::summarise(
    mean_precision = mean(precision),
    upper = quantile(precision, 0.95),
    lower = quantile(precision, 0.05)
  ) %>%
  dplyr::mutate(
    upper = dplyr::case_when(
      upper > 1 ~ 1,
      TRUE ~ upper
    ),
    lower = dplyr::case_when(
      lower < 0 ~ 0,
      TRUE ~ lower
    )
  )

color_names <- c("IDSA"="#1B9E77", 'All-cause'="#7570B3",
                 'Attributable'="#D95F02", 'Pragmatic'="#E7298A")

priors <- sensspec_dat %>%
  select(outcome, dataset, prior) %>%
  dplyr::distinct() %>%
  mutate(outcome = factor(case_when(outcome == 'idsa' ~ 'IDSA',
                                    outcome == 'allcause' ~ 'All-cause',
                                    outcome == 'attrib' ~ 'Attributable',
                                    outcome == 'pragmatic' ~ 'Pragmatic',
                                    TRUE ~ NA_character_),
                          levels = c("IDSA", 'All-cause', 'Attributable', 'Pragmatic')),
         prior = round(prior, 2)
  )

auprc_medians <- perf_dat %>%
  group_by(dataset, outcome) %>%
  summarize(med_auprc = median(pr_auc) %>% round(.,2)) %>%
  mutate(lower = med_auprc, upper = med_auprc) %>%
  mutate(outcome = factor(str_remove(outcome, "\n severity"),
                          levels = c("IDSA", 'All-cause', 'Attributable', 'Pragmatic')
                          ),
         dataset = case_when(dataset == 'Intersection of samples with all labels available' ~ "Intersection",
                             TRUE ~ dataset)
  )

prc_plot_grid <- prcurve_dat %>%
  filter(dataset != 'Intersection') %>%
  mutate(outcome = factor(case_when(
         outcome == 'idsa' ~ 'IDSA',
         outcome == 'allcause' ~ 'All-cause',
         outcome == 'attrib' ~ 'Attributable',
         outcome == 'pragmatic' ~ 'Pragmatic',
         TRUE ~ NA_character_
         ),
         levels = c("IDSA", 'All-cause', 'Attributable', 'Pragmatic'))
         ) %>%
  ggplot(aes(x = recall, y = mean_precision)) +
  geom_ribbon(aes(fill = outcome, ymin = lower, ymax = upper),
              alpha = 0.15) +
  geom_line(aes(color = outcome)) +
  geom_hline(data = priors %>% filter(dataset != 'int'),
             mapping = aes(yintercept = prior),
             linetype = 'dashed') +
  geom_text(data = priors %>% filter(dataset != 'int'),
            mapping = aes(x = 0.5, y = 0.78,
                          label = glue("baseline = {prior}")
            ),
            show.legend = FALSE,
            size = 3
            ) +
  geom_text(data = auprc_medians %>% filter(dataset != 'int'),
            mapping = aes(x = 0.5, y = 0.9,
                          label = glue('  AUPRC = {med_auprc}')
                          ),
            show.legend = FALSE,
            size = 3
            ) +
  scale_color_manual(values = color_names,
                     guide = guide_legend(label.position = "top")) +
  scale_fill_manual(values = color_names,
  ) +
  scale_y_continuous(expand = c(0, 0), limits = c(-0.01, 1.01)) +
  scale_x_continuous(expand = c(0, 0), limits = c(-0.01, 1.01)) +
  coord_equal() +
  labs(x = "Recall", y = "Precision") +
  facet_wrap("outcome",nrow=1) +
  theme_sovacool() +
  theme(text = element_text(size = 14, family = 'Helvetica'),
        legend.title = element_blank(),
        legend.position = 'none',
        strip.background = element_blank(),
        panel.spacing = unit(8, 'pt'),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
prc_plot_grid
```

:::{.notes}
ROC = trade-off between correctly predicting positive vs negative samples.

precision = $PPV = \frac{TP}{TP + FP}$

Out of samples predicted positive, how many correctly predicted positive.

sensitivity/recall = $TPR = \frac{TP}{TP + FN}$

Out of all positive samples, how many correctly predicted positive.
:::


## Top OTUs contributing to model performance

![](papers/severe-cdi/figures/feature-importance_full.png)

## Clinical value of severity prediction models

- The pragmatic severity model performed just as well as an EHR-based model.
- Decent model performance is not enough to justify model deployment.
- Open question: would deploying EHR and OTU-based models improve clinical outcomes?

## Overview

:::{.column width="72%"}
1. Improve methods for processing microbiome data.
1. Predict severe _C. difficile_ infections from gut microbiome composition.
1. **Contribute to democratizing data science.**
:::

## Democratizing reproducible data science

- Make data science tools more accessible to researchers from non-computational backgrounds.
- Disseminate user-friendly tools & curricula with OSI-approved licenses.
- Promote diversity, equity, and inclusion in data science.

## Addressing the gender gap in STEM

- 18% of CS degrees are awarded to women.
- U-M Bioinf PhD graduates: 25% women. The disparity begins at the application stage.
- Most of us (women in U-M bioinf) didn't learn to code until college or later.

:::{.fragment}
**Solution:** start a Girls Who Code club focused on teaching data science to high schoolers.
:::

## Intro to Python for Data Science
### for Girls Who Code at U-M DCMB

![](papers/girls-who-code/paper/lesson-modules.png)

:::{.aside}
Duda^\*^ and Sovacool^\*^ _et al._ (2021). [JOSE](https://doi.org/10.21105/jose.00138)
:::

:::{.notes}
teach high schoolers the basics of coding in Python for data science.
from knowing no programming to being able to analyze a data science and present
findings at the end of the club.

live coding. hands on lessons and practice notebooks.
pivot to flipped format for pandemic.

1. Each lesson begins with a recapping of the relevant core skills presented in the
previous lessons.
2. All lessons are designed to be taught via 15-minute live-coding sessions. This method
is used by The Carpentries and is demonstrated to be an effective method that
engages learners (Nederbragt et al., 2020; Wilson, 2016) since learners must actively
engage with the material and deal with errors and bugs as they arise.
3. Each lesson ends with a summary of core skills presented within the material.
4. Each short lesson is also accompanied by a subsequent 10-minute independent practice, providing further opportunity for practical experience implementing the coding
skill at hand and testing learners' understanding of the content.
:::

## Impact of Girls Who Code

- 135+ graduates of the club & summer camp.
- Graduates improve skills in coding, problem solving, collaboration, and self-confidence.

> Because of GWC, I learned about bioinformatics. I was very interested in it,
> because it combined my interests in programming and research...
> I'm pretty certain I want to go into bioinformatics now.

<br>

> I plan to go to college for Computer Science and get a robotics minor when
> my college offers it.
> GWC has inspired me to consider pursuing a Masters or PhD in
> CS as well as take some electives in Data Science.

## Coding for Reproducible Research

- Over 34,000 learners have attended Software Carpentry workshops worldwide since 2010, ranging from biologists to physicists to engineers and economists.
- U-M instance of Software Carpentry active since 2016.

![](img/swc-lessons.png)

:::{.aside}
https://software-carpentry.org/lessons/
:::

:::{.notes}

- Software Carpentry is an international non-profit that teaches grad students, postdocs, and other researchers how to perform reproducible computational science via interactive coding workshops.
- Over 34,000 learners have attended since 2010, ranging from biologists to physicists to engineers and economists.
- U-M instance of Software Carpentry active since 2016.
:::

## Integrated curriculum teaching R, Unix shell, & Git for reproducible research

![](papers/software-carpentry/paper/curriculum-overview.png)

:::{.aside}
Lapp^\*^ and Sovacool^\*^ _et al._ (2022). [JOSE](https://doi.org/10.21105/jose.00144)
:::

## Impact of Software Carpentry

Pilot workshop pre & post survey

![](papers/software-carpentry/paper/survey-results.png)

:::{.aside}
Lapp^\*^ and Sovacool^\*^ _et al._ (2022). [JOSE](https://doi.org/10.21105/jose.00144)
:::

:::{.notes}
New curriculum used in 7 workshops to date.
:::

## Reproducible ML pipelines with mikropml

:::{.absolute right=100 top=50}
`"meek-rope em el"`
:::

<br>

:::{.column width="75%"}
![](img/mikropml-pipeline.png)
:::

:::{.column width="20%"}
![](img/mikropml-snakemake.png){height=400px}
:::

:::{.aside}
TopÃ§uoÄŸlu^\*^, Lapp^\*^, Sovacool^\*^ _et al._ (2021). [JOSS](https://doi.org/10.21105/joss.03073)
:::

:::{.notes}

- Typical microbiologist lacks ML expertise
- Many microbiologists have enough computational skills to be "dangerous"
- Common pitfalls
  - Lack of transparency in method implementation
  - No separate held-out test data
  - Not reporting variation in the predictive performance on different folds of cross-validation, or cross-validation vs. testing performances

Goals

- Restructure our ML framework to improve reusability, scalability, & reproducibility.
- Strike a balance between easy-to-use interface for beginners with reasonable default options,
  with enough flexibility for advanced users to customize options.

best practices in swe

- GitFlow, issue tracking, peer review
- Unit tests + CI
- Document functions & vignettes
- Semantic versioning, changelog

:::

## mikropml impact {.smaller}

<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
<script async src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script>

:::{.column width="70%"}
![](img/plot-downloads-time_no-badge-1.png){height=550px}
:::

:::{.column width="15%"}
<br>
<br>

CRAN: <img src="https://cranlogs.r-pkg.org/badges/grand-total/mikropml">

conda-forge: ![](https://anaconda.org/conda-forge/r-mikropml/badges/downloads.svg)

<span class="__dimensions_badge_embed__" data-doi="10.21105/joss.03073" data-hide-zero-citations="true" data-style="large_rectangle" data-legend="hover-right"></span>

:::


:::{.notes}
:::{.column width="48%"}
**In the lab**

- CRC classification across taxonimic levels
- Mouse _C. diff_ colonization & clearance
- Mouse models of colitis
:::

:::{.column width="48%"}
**In the wild**

- Diet and antimicrobial resistance
- Evolution of grasses
- Psychology research
- Political science
:::
:::

## Summary

- Improved OTU clustering algorithms to enable ML for microbiome research.
- Applied ML to predict severe CDIs, demonstrating similar performance as EHR models.
- Contributed to democratizing data science for three key audiences: high schoolers, researchers, and novice ML practitioners.

![](img/frontispiece.png){fig-align="center"}

## Acknowledgements {.smaller}

TODO

:::{.column width="45%"}
**Schloss Lab**

Advisor: Pat Schloss <br>
Mentee: Megan Coden <br>
Sarah Lucas <br>
Courtney Armour <br>
Allison Mason <br>
Adena Collens

**alumni**

Nick Lesniak <br>
Sarah Tomkovich <br>
Katie McBride <br>
Jay Moltzau <br>
BegÃ¼m TopÃ§uoÄŸlu <br>
Will Close <br>
Joshua Stough <br>
Ada Hagan <br>
Kaitlin Flynn <br>
:::

::::{.column width="45%"}
**Collaborators**

Jenna Wiens <br>
Vince Young <br>
Krishna Rao <br>

**Funding**

:::{.small}
NIH T32 GM070449 <br>
NIH U01AI124255 <br>
:::
::::

## post-PhD plans

Bioinformatics Software Engineer for Frederick National Lab (NIH/NCI)

## Congratulations! &nbsp; ðŸŽ‰

:::{.big-center}
_You've unlocked the backup slides_
:::

## 5-fold cross validation

![](img/grid_search_cross_validation.png){height=500px}

::: {.aside}
sklearn docs: <https://scikit-learn.org/stable/modules/cross_validation.html>
:::

## Decision trees

![](img/decision-trees.png)

## Random forest

![](img/random-forest.png)

## A more fair comparison? {.smaller}

```{r auroc_facet}
auroc_facet_plot <- perf_dat %>%
    rename(trainset = cv_metric_AUC,
           testset = AUROC) %>%
    pivot_longer(c(trainset, testset),
                 names_to = "data_partition",
                 values_to = 'AUROC'
                 )  %>%
    ggplot(aes(x = AUROC, y = outcome, color = data_partition)) +
    geom_vline(xintercept = 0.5, linetype = "dashed") +
    geom_boxplot() +
    stat_summary(fun = median,
                 geom = "text",
                 show.legend = FALSE,
                 mapping = aes(label = round(after_stat(x),2)),
                 position = position_nudge(x = 0.2, y = c(-0.1, 0.1))) +
    facet_wrap('dataset', ncol = 2) +
    scale_color_grey() +
    scale_x_continuous(expand = c(0, 0), limits = c(0.3, 1.01)) +
    theme_sovacool() +
    theme(
        plot.margin = unit(x = c(0, 0, 0, 0), units = "pt"),
        axis.title.y = element_blank(),
        legend.position = 'top',
        legend.margin = margin(0, 0, 0, 0, unit = "pt"),
        legend.title = element_blank(),
        text = element_text(size = 14)
    )

auroc_facet_plot
```

```{r int}
ncases_int <- read_csv('papers/severe-cdi/data/process/cases_int_metadata.csv') %>% nrow()
```

:::{.absolute bottom=5 left=100 width="40%" .color-ash}
**full** - all samples available; different number of samples between outcomes.
:::

:::{.absolute bottom=5 right=50 width="40%" .color-ash}
**int** - intersection, i.e. only samples that have all three outcome labels (n=`r ncases_int`).
:::


## Limitation: class imbalance

- Imbalanced classes with many negatives can inflate the ROC (sensitivity vs 1-specificity).
- The baseline PRC (precision vs recall) depends on the frequency of positives, but the severity definitions each have different frequencies of positives.

:::{.absolute right=2 bottom=5 width="45%"}
![](img/wiki-conf-mat.png)
:::

:::{.absolute left=2 bottom=200 width="52%" .filled-box}
```{r positives}
counts %>%
    kable(format.args = list(big.mark = ',')) %>%
    kableExtra::kable_styling(font_size = 22)
```
:::

:::{.notes}
precision: out of samples predicted to be positive, how many are correct

recall: out of positively labelled samples, how many are predicted positive
:::

## Solution: calculate the balanced precision

Introduced by
[Wu _et al._ (2021). AJHG.](https://doi.org/10.1016/j.ajhg.2021.08.012) Improved pathogenicity prediction for rare human missense variants.

<br>

#### Equation 7

$$
AUBPRC = \frac{AUPRC \times (1 - prior)}
{AUPRC \times (1 - prior) + (1 - AUPRC) \times prior}
$$

:::{.aside}
_prior_ = frequency of positives

_AUBPRC_ = area under the **balanced precision**-recall curve
:::

:::{.notes}
https://en.wikipedia.org/wiki/Bayes%27_theorem
:::

## Balanced Precision {.smaller}
Performance on the test set for Random Forest models trained on 100x train/test splits of each dataset

```{r aubprc_box}
aubprc_box <- perf_dat %>%
    filter(dataset != 'int') %>%
    ggplot(aes(x = bpr_auc, y = outcome)) +
    geom_vline(xintercept = 0.5, linetype = "dashed") +
    geom_boxplot() +
    stat_summary(fun = median,
                 geom = "text",
                 show.legend = FALSE,
                 mapping = aes(label = round(after_stat(x),2)),
                 position = position_nudge(x = 0.04, y = 0.1)) +
    labs(x = 'AUBPRC') +
    scale_x_continuous(expand = c(0, 0), limits = c(0.3, 1.01)) +
    theme_sovacool() +
    theme(
        plot.margin = unit(x = c(0, 0, 0, 0), units = "pt"),
        axis.title.y = element_blank(),
        legend.position = 'top',
        legend.margin = margin(0, 0, 0, 0, unit = "pt"),
        legend.title = element_blank(),
        text = element_text(size = 14)
    )
aubprc_box
```

